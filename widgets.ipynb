{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run widgets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32a356ebf9b4c1e8355c1a3f64118a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h2>Segmentation task: tls_park</h2>'), Button(description='Run', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "s = Segmentation(\n",
    "    'tls_park', \n",
    "    training_repo='/data1/sat/dataset_tls_park_444/train.txt',\n",
    "    testing_repo='/data1/sat/dataset_tls_park_444/test.txt',\n",
    "    host='10.10.77.61',\n",
    "    port=8500,\n",
    "    #port=8400,\n",
    "    img_height=480,\n",
    "    img_width=480,\n",
    "    model_repo='/data1/sat/xolive/models/model_tls_park_debug',\n",
    "    nclasses=2,\n",
    "    #template='deeplab_vgg16',\n",
    "    iterations=15000,\n",
    "    test_interval=500,\n",
    "    snapshot_interval=1000,\n",
    "    batch_size=5,\n",
    "    test_batch_size=1,\n",
    "    noise_prob=0.001,\n",
    "    class_weights=[0.1, 1.0],\n",
    "    model_postfix='test_park_xo3',\n",
    "    weights='/data1/segmentation/vgg16_init_deeplab.caffemodel',\n",
    "    gpuid=2\n",
    ")#.run()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07988816852f4475b051a4cb4867d5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h2>Classification task: xo_bbc_5_classes</h2>'), Button(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = Classification(\n",
    "    'xo_bbc_5_classes', \n",
    "        training_repo='/data1/xolive/bbc_sounds/sounds_dataset_1.0/train/',\n",
    "        testing_repo='/data1/xolive/bbc_sounds/sounds_dataset_1.0/test/',\n",
    "                   host='10.10.77.61',\n",
    "        port=8500,\n",
    "        model_repo='/data1/bbc_sounds/bbc_5_classes',\n",
    "        layers='[\"1CR32\", \"1CR64\", \"1CR128\", \"1024\"]',\n",
    "        template='convnet',\n",
    "        gpuid=1,\n",
    "                   img_width=257,\n",
    "                   img_height=257\n",
    "        )#.run()\n",
    "c\n",
    "# TODO unchanged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9040d61afb2e4925871029b10bfb8f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h2>Classification task: kaggle</h2>'), Button(description='Run', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = Classification('kaggle', \n",
    "                    training_repo='/data1/kaggle/dogs_cats/train/',\n",
    "                   tsplit=.2,\n",
    "                    host='10.10.77.61',\n",
    "                    port=8500,\n",
    "                    model_repo='/data1/xolive/models/kaggle',\n",
    "                    template='convnet',\n",
    "                    gpuid=1,\n",
    "                   layers=['1CR32','1CR64','1CR128','1024'],\n",
    "                   img_width=150,\n",
    "                   img_height=150,\n",
    "                   mirror=True,\n",
    "                   rotate=True,\n",
    "        )#.run()\n",
    "c\n",
    "# TODO unchanged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01b09b75df494f9089b28240404707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h2>Detection task: eoliennes</h2>'), Button(description='Run', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = Detection(\n",
    "    \"eoliennes\",\n",
    "    training_repo= \"/data1/sat/dataset_windturbine_europe_16_test/train.txt\",\n",
    "    testing_repo= \"/data1/sat/dataset_windturbine_europe_16_test/test.txt\",\n",
    "    host='10.10.77.61',\n",
    "    port=8500,\n",
    "    model_repo='/data1/xolive/models/detection',\n",
    "    gpuid=0,\n",
    "    img_width=300,\n",
    "    img_height=300,\n",
    "    snapshot_interval=1000,\n",
    "    iterations=5000,\n",
    "    template=\"ssd_300\",\n",
    "    mirror=True,\n",
    "    rotate=True, # no default\n",
    "    finetune=True,\n",
    "    weights=\"/data1/detection/VGG_ILSVRC_16_layers_fc_reduced.caffemodel\",\n",
    "    batch_size=24,\n",
    "    test_batch_size=4,\n",
    "    nclasses=2,\n",
    ")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSV(MLWidget):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 sname: str,\n",
    "                 *args,\n",
    "                 training_repo: Path = None,\n",
    "                 model_repo: Path = None,\n",
    "                 host: str = \"localhost\",\n",
    "                 port: int = 1234,\n",
    "                 tsplit: float = 0.01,\n",
    "                 base_lr: float = 0.01,\n",
    "                 iterations: int = 100,\n",
    "                 test_interval: int = 1000,\n",
    "                 step_size: int = 15000,\n",
    "                 dropout: float = .2,\n",
    "                 destroy: bool = False,\n",
    "                 resume: bool = False,\n",
    "                 finetune: bool = False,\n",
    "                 weights: Optional[Path] = None,\n",
    "                 nclasses: int = 2,\n",
    "                 batch_size: int = 128,\n",
    "                 test_batch_size: int = 16,\n",
    "                 gpuid: int = 0,\n",
    "                 mllib: str = 'caffe',\n",
    "                 lregression: bool = False,\n",
    "                 scale: bool= False,\n",
    "                 csv_id: str = '',\n",
    "                 csv_separator: str= ',',\n",
    "                 csv_ignore: List[str] = [],\n",
    "                 csv_label: str,\n",
    "                 csv_label_offset: int = 0,\n",
    "                 csv_categoricals: List[str] = [],\n",
    "                 scale_pos_weight: float = 1.0,\n",
    "                 shuffle: bool = True\n",
    "                 \n",
    "                ):\n",
    "        local_vars = locals()\n",
    "        params = {\n",
    "            # no access to eval(k) inside the comprehension\n",
    "            k: (eval(k, local_vars), v)\n",
    "            for k, v in get_type_hints(self.__init__).items()\n",
    "            if k not in [\"return\", \"sname\"]\n",
    "        }\n",
    "\n",
    "        super().__init__(sname, params)\n",
    "        \n",
    "        self._displays = HTML(\n",
    "            value=pd.read_csv(training_repo).sample(5)._repr_html_()\n",
    "        )\n",
    "        \n",
    "        self._img_explorer = VBox(\n",
    "            [\n",
    "                #HBox([HBox([self.train_labels, self.test_labels])]),\n",
    "                #self.file_list,\n",
    "                self._displays,\n",
    "                self.output,\n",
    "            ],\n",
    "            layout=Layout(width=\"650px\"),\n",
    "        )\n",
    "\n",
    "        self._main_elt = HBox(\n",
    "            [self._configuration, self._img_explorer],\n",
    "            layout=Layout(width=\"900px\"),\n",
    "        )\n",
    "    \n",
    "    def hard_clear(self, *_):\n",
    "        host = self.host.value\n",
    "        port = self.port.value\n",
    "    \n",
    "        body = {\n",
    "           \"mllib\":\"caffe\",\n",
    "           \"description\": self.sname,\n",
    "           \"parameters\":{\n",
    "             \"input\":{\n",
    "             },\n",
    "             \"mllib\":{\n",
    "             }\n",
    "           },\n",
    "           \"model\":{\n",
    "             \"repository\": self.model_repo.value,\n",
    "             \"create_repository\": True\n",
    "           }\n",
    "        }\n",
    "        \n",
    "        logging.info(\n",
    "            \"Sending request http://{host}:{port}/services/{sname}\".format(\n",
    "                host=host, port=port, sname=self.sname\n",
    "            )\n",
    "        )\n",
    "        c = requests.get(\n",
    "            \"http://{host}:{port}/services/{sname}\".format(\n",
    "                host=host, port=port, sname=self.sname\n",
    "            )\n",
    "        )\n",
    "        logging.info(\n",
    "            \"Current state of service '{sname}': {json}\".format(\n",
    "                sname=self.sname, json=json.dumps(c.json(), indent=2)\n",
    "            )\n",
    "        )\n",
    "        if c.json()[\"status\"][\"msg\"] != \"NotFound\":\n",
    "            self.clear()\n",
    "            logging.warning(\n",
    "                (\n",
    "                    \"Since service '{sname}' was still there, \"\n",
    "                    \"it has been fully cleared: {json}\"\n",
    "                ).format(sname=self.sname, json=json.dumps(c.json(), indent=2))\n",
    "            )\n",
    "    \n",
    "    @MLWidget.output.capture(clear_output=True)\n",
    "    def run(self, *_):\n",
    "        \n",
    "        host = self.host.value\n",
    "        port = self.port.value\n",
    "    \n",
    "        body = {\n",
    "           \"mllib\":\"caffe\",\n",
    "           \"description\": self.sname,\n",
    "           \"type\":\"supervised\",\n",
    "           \"parameters\":{\n",
    "             \"input\":{\n",
    "               \"connector\":\"csv\",\n",
    "                \"labels\": self.csv_label.value,\n",
    "                 \"db\": False\n",
    "             },\n",
    "             \"mllib\":{\n",
    "               \"template\":\"mlp\",\n",
    "               \"nclasses\":7,\n",
    "               \"layers\":[150,150,150],\n",
    "               \"activation\":\"prelu\",\n",
    "               \"db\": True\n",
    "             }\n",
    "           },\n",
    "           \"model\":{\n",
    "             \"templates\":\"../templates/caffe/\",\n",
    "             \"repository\": self.model_repo.value,\n",
    "             \"create_repository\": True\n",
    "           }\n",
    "        }\n",
    "        \n",
    "        if self.lregression.value:\n",
    "            body['parameters']['mllib']['template'] = 'lregression'\n",
    "            del body['parameters']['mllib']['layes']\n",
    "        else:\n",
    "            body['parameters']['mllib']['dropout'] = self.dropout.value\n",
    "            \n",
    "        if self.mllib.value == 'xgboost':\n",
    "            body['parameters']['mllib']['db'] = False\n",
    "            \n",
    "        if self.finetune.value:\n",
    "            body['parameters']['mllib']['finetuning'] = True\n",
    "            body['parameters']['mllib']['weights'] = self.weights.value\n",
    "            \n",
    "        \n",
    "        logging.info(\n",
    "            \"Sending request http://{host}:{port}/services/{sname}\".format(\n",
    "                host=host, port=port, sname=self.sname\n",
    "            )\n",
    "        )\n",
    "        c = requests.get(\n",
    "            \"http://{host}:{port}/services/{sname}\".format(\n",
    "                host=host, port=port, sname=self.sname\n",
    "            )\n",
    "        )\n",
    "        logging.info(\n",
    "            \"Current state of service '{sname}': {json}\".format(\n",
    "                sname=self.sname, json=json.dumps(c.json(), indent=2)\n",
    "            )\n",
    "        )\n",
    "        if c.json()[\"status\"][\"msg\"] != \"NotFound\":\n",
    "            self.clear()\n",
    "            logging.warning(\n",
    "                (\n",
    "                    \"Since service '{sname}' was still there, \"\n",
    "                    \"it has been fully cleared: {json}\"\n",
    "                ).format(sname=self.sname, json=json.dumps(c.json(), indent=2))\n",
    "            )\n",
    "\n",
    "        logging.info(\n",
    "            \"Creating service '{sname}':\\n {body}\".format(\n",
    "                sname=self.sname, body=json.dumps(body, indent=2)\n",
    "            )\n",
    "        )\n",
    "        c = requests.put(\n",
    "            \"http://{host}:{port}/services/{sname}\".format(\n",
    "                host=host, port=port, sname=self.sname\n",
    "            ),\n",
    "            json.dumps(body),\n",
    "        )\n",
    "\n",
    "        if c.json()['status']['code'] != 200:\n",
    "            logging.warning(\n",
    "                \"Reply from creating service '{sname}': {json}\".format(\n",
    "                    sname=self.sname, json=json.dumps(c.json(), indent=2)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            logging.info(\n",
    "            \"Reply from creating service '{sname}': {json}\".format(\n",
    "                sname=self.sname, json=json.dumps(c.json(), indent=2)\n",
    "            )\n",
    "        )\n",
    "            \n",
    "        body = {\n",
    "       \"service\":self.sname,\n",
    "       \"async\":True,\n",
    "       \"parameters\":{\n",
    "         \"mllib\":{\n",
    "           \"gpu\":True,\n",
    "             'gpuid': self.gpuid.value,\n",
    "             'resume': self.resume.value,\n",
    "           \"solver\":{\n",
    "             \"iterations\":self.iterations.value,\n",
    "               'iter_size': 1,\n",
    "             \"test_interval\":self.test_interval.value,\n",
    "               'test_initialization': False,\n",
    "             \"base_lr\": self.base_lr.value,\n",
    "               'solver_type': 'ADAM'\n",
    "           },\n",
    "           \"net\":{\n",
    "             \"batch_size\": self.batch_size.value,\n",
    "               'test_batch_size': self.test_batch_size.value\n",
    "           }\n",
    "         },\n",
    "         \"input\":{\n",
    "         \"label_offset\":self.csv_label_offset.value,\n",
    "         \"label\":self.csv_label.value,\n",
    "         \"id\": self.csv_id.value,\n",
    "         \"separator\":self.csv_separator.value,\n",
    "         \"shuffle\":self.shuffle.value,\n",
    "         \"test_split\": self.tsplit.value,\n",
    "         \"scale\":self.scale.value,\n",
    "             'db': False,\n",
    "             'scale': self.scale.value,\n",
    "             'ignore': self.csv_ignore.value,\n",
    "             'categoricals': self.csv_categoricals.value\n",
    "         },\n",
    "         \"output\":{\n",
    "           \"measure\":[\"cmdiag\", \"cmfull\", \"mcll\",\"f1\"]\n",
    "         }\n",
    "       },\n",
    "       \"data\":[self.training_repo.value]\n",
    "     }\n",
    "        \n",
    "        if self.nclasses.value == 2:\n",
    "            body['parameters']['output']['measure'].append('auc')\n",
    "        \n",
    "        logging.info(\n",
    "            \"Start training phase: {body}\".format(body=json.dumps(body, indent=2))\n",
    "        )\n",
    "        c = requests.post(\n",
    "            \"http://{host}:{port}/train\".format(host=host, port=port),\n",
    "            json.dumps(body),\n",
    "        )\n",
    "        logging.info(\n",
    "            \"Reply from training service '{sname}': {json}\".format(\n",
    "                sname=self.sname, json=json.dumps(c.json(), indent=2)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(json.dumps(c.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV('forest',\n",
    "        host='10.10.77.61',\n",
    "        port=8500,\n",
    "        training_repo=\"/data1/xolive/forest_type/train.csv\",\n",
    "        model_repo=\"/data1/xolive/models/forest\",\n",
    "        csv_label='Cover_Type'\n",
    "        ).hard_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (system)",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
